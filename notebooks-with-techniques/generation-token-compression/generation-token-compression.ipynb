{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation Token Compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Helper Functions and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "import json\n",
    "import time\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import copy\n",
    "import textwrap\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "def aoai_call(system_message,prompt,model):\n",
    "    client = AzureOpenAI(\n",
    "        api_version=os.getenv(\"API_VERSION\"),\n",
    "        azure_endpoint=os.getenv(\"AZURE_ENDPOINT\"),\n",
    "        api_key=os.getenv(\"API_KEY\")\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    e2e_time = end_time - start_time\n",
    "\n",
    "    result=json.loads(completion.model_dump_json(indent=2))\n",
    "    prompt_tokens=result[\"usage\"][\"prompt_tokens\"]\n",
    "    completion_tokens=result[\"usage\"][\"completion_tokens\"]\n",
    "    completion_text=result[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    return result,prompt_tokens,completion_tokens,completion_text,e2e_time\n",
    "\n",
    "model=os.getenv(\"MODELGPT432k\")\n",
    "\n",
    "# Read essay from a text file\n",
    "with open('sales_report.txt', 'r') as f:\n",
    "    sales_report = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case: Summarising a report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A: Naive summarisation, using the model's default verbosity\n",
    "\n",
    "**Time taken: 20 seconds**\n",
    "\n",
    "The model has a natural amount of verbosity- that is, the amount it chooses to say. Certain models will give long explanations to questions, other models may tend to give a more succinct answer. The total time taken for the model to finish is largely impacted by this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Tokens: 1554\n",
      "Completion Tokens: 246\n",
      "Time taken: 20.38 seconds\n"
     ]
    }
   ],
   "source": [
    "system_message=\"\"\"\n",
    "You are a helpful AI assistant.\n",
    "\"\"\"\n",
    "prompt=f\"\"\"\n",
    "Document to summarise:\n",
    "{sales_report}\n",
    "Summarise this document. Include the type of game, the sales performance by region, the performance of the launch, and feedback about the launch.\n",
    "\"\"\"\n",
    "\n",
    "result,prompt_tokens,completion_tokens,completion_text,e2e_time=aoai_call(system_message,prompt,model)\n",
    "print(f\"Prompt Tokens: {prompt_tokens}\")\n",
    "print(f\"Completion Tokens: {completion_tokens}\")\n",
    "print(f\"Time taken: {e2e_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The document discusses the global launch of a flagship real time strategy (RTS) video game. The game, known for its immersive gameplay, dynamic environment, and strategic planning elements, demonstrated impressive sales performance. \\n\\nIn the North American market, the game yielded sales of 1.5 million units, far exceeding the initial projections of one million units. The international markets mirrored this success. Europe recorded sales of 1.8 million units and Asia 2 million units. Though comparatively lower, the Latin America and Africa markets showed potential with sales of 0.5 million and 0.3 million units respectively. \\n\\nDespite the impressive sales, user feedback indicated issues with the game's micro-transaction system. Users across various regions perceived the system negatively, seeing it as a barrier to progress within the game without spending excessive real money. This criticism has led to the company noticing the need for immediate improvements in balancing user satisfaction and profit margins. \\n\\nFuture plans include re-evaluating the criticized micro-transaction system to make it fair, transparent, and contributory to the overall gaming experience rather than making the game unbalanced or overly expensive. The company also plans to devise market-specific strategies to penetrate further into underperforming markets.\\n\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B: Summarisation with a focus on conciseness\n",
    "\n",
    "**Time taken: 8.5 seconds**\n",
    "\n",
    "By simply asking the model to be more succinct, the LLM spends less time generating tokens, making the overall repsonse much faster.\n",
    "\n",
    "Of course, this may mean the answer is less complete, or doesn't fully meet the user's expectations. For backend processes, such as explaining the reason for a decision, this is often acceptable. For customer facing applications, this may also be ok, but testing is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Tokens: 1568\n",
      "Completion Tokens: 130\n",
      "Time taken: 14.86 seconds\n",
      "The document refers to the global launch of a leading Real Time Strategy (RTS) video game. The game has exceeded sales expectations in North America (1.5 million units), Europe (1.8 million units), and Asia (2 million units), with promising potential in Latin America (0.5 million units) and Africa (0.3 million units). However, feedback from players globally criticizes the game's micro-transaction system, which they find excessively expensive. Despite this, the game's strong sales reflect its overall success, and the company plans to revamp the micro-transaction system and tailor marketing strategies for underperforming markets.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "system_message=\"\"\"\n",
    "You are a helpful AI assistant.\n",
    "\"\"\"\n",
    "prompt=f\"\"\"\n",
    "Document to summarise:\n",
    "{sales_report}\n",
    "Summarise this document. Include the type of game, the sales performance by region, the performance of the launch, and feedback about the launch. Be as succint as possible, using as few words as possible.\n",
    "\"\"\"\n",
    "\n",
    "result,prompt_tokens,completion_tokens,completion_text,e2e_time=aoai_call(system_message,prompt,model)\n",
    "print(f\"Prompt Tokens: {prompt_tokens}\")\n",
    "print(f\"Completion Tokens: {completion_tokens}\")\n",
    "print(f\"Time taken: {e2e_time:.2f} seconds\")\n",
    "print(completion_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C: Few shot prompting\n",
    "\n",
    "**Time taken: 8.2 seconds**\n",
    "\n",
    "The best approach is to use few shot prompting to help guide the model, to better optimise the balance between succinctness and completeness. This also has the advantage of providing a structured output, which will be consistent across the application (for example, every report being summarised will now be in the same format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Tokens: 2004\n",
      "Completion Tokens: 72\n",
      "Time taken: 8.08 seconds\n",
      "Product Type:\n",
      "RTS\n",
      "\n",
      "Sales:\n",
      "NA: 1.5M\n",
      "EU: 1.8M\n",
      "Asia: 2.0M\n",
      "Latin America: 0.5M\n",
      "Africa: 0.3M\n",
      "\n",
      "Performance:\n",
      "1.5 times projections.\n",
      "\n",
      "Feedback:\n",
      "Mixed; praised for mechanics but criticized for micro-transaction system.\n"
     ]
    }
   ],
   "source": [
    "system_message=\"\"\"\n",
    "You are a helpful AI assistant.\n",
    "\"\"\"\n",
    "prompt=f\"\"\"\n",
    "\n",
    "\n",
    "You must use the below structure for your summary.\n",
    "START_EXAMPLE:\n",
    "Document:\n",
    "Product Briefing Document\n",
    "I. Product Overview\n",
    "Product: \"Battlefield Conquerors\"\n",
    "Battlefield Conquerors is an immersive, action-packed First-Person Shooter (FPS) game that thrusts players into a gritty, fast-paced world of strategic warfare. Skill, precision, and quick thinking are the keys to victory in this adrenaline-fueled gaming experience.\n",
    "II. Sales Performance\n",
    "Battlefield Conquerors has achieved robust sales across multiple global regions, effectively penetrating the gaming market.\n",
    "North America (NA)\n",
    "In North America, the game has resonated particularly well, with a total of 1.5 million units sold. This success can be attributed to its strategic marketing campaign and the region's affinity for the FPS genre.\n",
    "Europe (EU)\n",
    "Europe has emerged as the game's most successful region in terms of sales, with an impressive 2.0 million units sold. The game's realistic graphics, dynamic gameplay, and stimulating storylines have been lauded by European gamers.\n",
    "Asia-Pacific (APAC)\n",
    "In the APAC region, Battlefield Conquerors has sold 1.0 million units. This solid performance is a testament to its broad appeal and the successful localization of the game's content for these markets.\n",
    "III. Financial Performance\n",
    "Battlefield Conquerors has not only met its financial targets but exceeded them. The game has achieved a performance of 1.2 times its initial budget, demonstrating its profitability and the successful return on investment.\n",
    "IV. Customer Feedback\n",
    "Customer feedback for Battlefield Conquerors has been overwhelmingly positive. Players have praised the game's innovative mechanics, immersive environment, and challenging gameplay.\n",
    "However, some concerns have been raised regarding the game's loading times. These issues have been acknowledged and are currently being addressed by the development team to ensure a seamless and uninterrupted gaming experience for all users moving forward.\n",
    "In conclusion, Battlefield Conquerors is a successful and profitable product, demonstrating strong sales performance across multiple regions. The few areas of improvement identified are being addressed to ensure continued success and customer satisfaction.\n",
    "\n",
    "Summary:\n",
    "Product Type:\n",
    "FPS\n",
    "\n",
    "Sales:\n",
    "NA: 1.5M\n",
    "EU: 2.0M\n",
    "APAC: 1.0M\n",
    "\n",
    "Performance:\n",
    "1.2 times budget.\n",
    "\n",
    "Feedback:\n",
    "Overall positive. Some concerns around loading times.\n",
    "END_EXAMPLE\n",
    "\n",
    "Document:\n",
    "{sales_report}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "result,prompt_tokens,completion_tokens,completion_text,e2e_time=aoai_call(system_message,prompt,model)\n",
    "print(f\"Prompt Tokens: {prompt_tokens}\")\n",
    "print(f\"Completion Tokens: {completion_tokens}\")\n",
    "print(f\"Time taken: {e2e_time:.2f} seconds\")\n",
    "print(completion_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case: Classification\n",
    "\n",
    "The imapact of this technique is proportionate to the number of documents being classified in series. There are other similar concepts that could be applied, by providing \"codes\" for the LLM to use to save time generating tokens.\n",
    "\n",
    "For more advanced techniques, see parallelization. These techniques can be combined for even greater speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_to_classify = \"\"\"[\n",
    "    \"Scientific research has led to significant advancements in medicine and healthcare.\",  \n",
    "    \"CLIP (Contrastive Language-Image Pretraining) - OpenAI's model that understands images in the context of natural language\",  \n",
    "    \"Science has contributed to our understanding of the natural world and the universe.\",  \n",
    "    \"Codex - OpenAI's AI system that can understand and generate code, powering GitHub Copilot\",  \n",
    "    \"GPT-4 - OpenAI's rumored next iteration of their language model with anticipated improvements\",  \n",
    "    \"Azure AI - Microsoft's suite of AI services, including machine learning, cognitive services, and conversational AI\",  \n",
    "     \"The collaboration and exchange of scientific knowledge across international borders have facilitated global progress in various fields.\" ,\n",
    "     \"Scientific innovations have improved communication and connectivity through technology.\", \n",
    "    \"Microsoft Turing Models - A series of large-scale language models developed by Microsoft\",  \n",
    "    \"Microsoft Project Brainwave - Real-time AI platform for cloud and edge computing\",  \n",
    "    \"Microsoft AI for Earth - A program applying AI to environmental challenges\",  \n",
    "    \"Microsoft AI for Health - An initiative leveraging AI for health-related research\",  \n",
    "    \"Scientific innovations have improved communication and connectivity through technology.\",  \n",
    "    \"OpenAI's API - Providing access to GPT-3 and other models for various applications\",   \n",
    "    \"Scientific research has led to significant advancements in medicine and healthcare.\",  \n",
    "    \"CLIP (Contrastive Language-Image Pretraining) - OpenAI's model that understands images in the context of natural language\",  \n",
    "    \"Science has contributed to our understanding of the natural world and the universe.\",  \n",
    "    \"Codex - OpenAI's AI system that can understand and generate code, powering GitHub Copilot\",  \n",
    "    \"GPT-4 - OpenAI's rumored next iteration of their language model with anticipated improvements\",  \n",
    "    \"Azure AI - Microsoft's suite of AI services, including machine learning, cognitive services, and conversational AI\",  \n",
    "     \"The collaboration and exchange of scientific knowledge across international borders have facilitated global progress in various fields.\" ,\n",
    "     \"Scientific innovations have improved communication and connectivity through technology.\", \n",
    "    \"Microsoft Turing Models - A series of large-scale language models developed by Microsoft\",  \n",
    "    \"Microsoft Project Brainwave - Real-time AI platform for cloud and edge computing\",  \n",
    "    \"Microsoft AI for Earth - A program applying AI to environmental challenges\",  \n",
    "    \"Microsoft AI for Health - An initiative leveraging AI for health-related research\",  \n",
    "    \"Scientific innovations have improved communication and connectivity through technology.\",  \n",
    "    \"OpenAI's API - Providing access to GPT-3 and other models for various applications\",   \n",
    "]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A: Classifying documents using the full category name\n",
    "\n",
    "**Time taken: 12.5 seconds**\n",
    "\n",
    "Here the model is providing the classification labels as the full text of the category name. This takes additional time, as more tokens are required per category name classified. The model has already made the determination of the class, but it takes additional time to convey that information to the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Tokens: 694\n",
      "Completion Tokens: 175\n",
      "Time taken: 9.67 seconds\n",
      "[SCIENCE, ARTIFICIAL INTELLIGENCE, SCIENCE, ARTIFICIAL INTELLIGENCE, ARTIFICIAL INTELLIGENCE, ARTIFICIAL INTELLIGENCE, SCIENCE, SCIENCE, ARTIFICIAL INTELLIGENCE, ARTIFICIAL INTELLIGENCE, ARTIFICIAL INTELLIGENCE, ARTIFICIAL INTELLIGENCE, SCIENCE, ARTIFICIAL INTELLIGENCE, SCIENCE, ARTIFICIAL INTELLIGENCE, SCIENCE, ARTIFICIAL INTELLIGENCE, ARTIFICIAL INTELLIGENCE, ARTIFICIAL INTELLIGENCE, SCIENCE, SCIENCE, ARTIFICIAL INTELLIGENCE, ARTIFICIAL INTELLIGENCE, ARTIFICIAL INTELLIGENCE, ARTIFICIAL INTELLIGENCE, SCIENCE, ARTIFICIAL INTELLIGENCE]\n"
     ]
    }
   ],
   "source": [
    "system_message=\"\"\"\n",
    "You are an helpful AI assistant that categorizes text in one of these categories : [A]: SCIENCE, [B]: ARTIFICIAL INTELLIGENCE, [C]: ART, [D]: HUMANITIES. \n",
    "Do not add any additional information.\n",
    "\n",
    "DOCUMENTS_TO_CLASSIFY:\n",
    "[\"GPT-3 (Generative Pre-trained Transformer 3) - OpenAI's powerful language model capable of writing like a human\",  \n",
    "\"Pigeons’ Backflips Linked to Genetics Scientists have unraveled the genetic basis behind a fascinating avian behavior\",\n",
    "]\n",
    "Example: [ARTIFICIAL INTELLIGENCE, SCIENCE]\n",
    "\"\"\"\n",
    "prompt=f\"\"\"\n",
    "DOCUMENTS_TO_CLASSIFY:\n",
    "{documents_to_classify}\n",
    "\"\"\"\n",
    "\n",
    "result,prompt_tokens,completion_tokens,completion_text,e2e_time=aoai_call(system_message,prompt,model)\n",
    "print(f\"Prompt Tokens: {prompt_tokens}\")\n",
    "print(f\"Completion Tokens: {completion_tokens}\")\n",
    "print(f\"Time taken: {e2e_time:.2f} seconds\")\n",
    "print(completion_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B: Use Categories to reduce the number of tokens generated\n",
    "\n",
    "**Time taken: 4 seconds**\n",
    "\n",
    "By assigning codes to each of the categories, the LLM only has to generate a single token per document classified. This is significantly faster. The codes can then be mapped back to the original class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Tokens: 712\n",
      "Completion Tokens: 84\n",
      "Time taken: 7.18 seconds\n",
      "[\"A\", \"B\", \"A\", \"B\", \"B\", \"B\", \"A\", \"A\", \"B\", \"B\", \"B\", \"B\", \"A\", \"B\", \"A\", \"B\", \"A\", \"B\", \"B\", \"B\", \"A\", \"A\", \"B\", \"B\", \"B\", \"B\", \"A\", \"B\"]\n"
     ]
    }
   ],
   "source": [
    "system_message=\"\"\"\n",
    "You are an helpful AI assistant that categorizes text in one of these categories : [A]: SCIENCE, [B]: ARTIFICIAL INTELLIGENCE, [C]: ART, [D]: HUMANITIES. \n",
    "Do not add any additional information. Only responde with the code for the category. For example, if it is SCIENCE, respond with [A].\n",
    "\n",
    "DOCUMENTS_TO_CLASSIFY:\n",
    "[\"GPT-3 (Generative Pre-trained Transformer 3) - OpenAI's powerful language model capable of writing like a human\",  \n",
    "\"Pigeons’ Backflips Linked to Genetics Scientists have unraveled the genetic basis behind a fascinating avian behavior\",\n",
    "]\n",
    "Example: [\"B\", \"A\"]\n",
    "\"\"\"\n",
    "prompt=f\"\"\"\n",
    "DOCUMENTS_TO_CLASSIFY:\n",
    "{documents_to_classify}\n",
    "\"\"\"\n",
    "\n",
    "result,prompt_tokens,completion_tokens,completion_text,e2e_time=aoai_call(system_message,prompt,model)\n",
    "print(f\"Prompt Tokens: {prompt_tokens}\")\n",
    "print(f\"Completion Tokens: {completion_tokens}\")\n",
    "print(f\"Time taken: {e2e_time:.2f} seconds\")\n",
    "print(completion_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SCIENCE', 'ARTIFICIAL INTELLIGENCE', 'SCIENCE', 'ARTIFICIAL INTELLIGENCE', 'ARTIFICIAL INTELLIGENCE', 'ARTIFICIAL INTELLIGENCE', 'SCIENCE', 'SCIENCE', 'ARTIFICIAL INTELLIGENCE', 'ARTIFICIAL INTELLIGENCE', 'ARTIFICIAL INTELLIGENCE', 'ARTIFICIAL INTELLIGENCE', 'SCIENCE', 'ARTIFICIAL INTELLIGENCE', 'SCIENCE', 'ARTIFICIAL INTELLIGENCE', 'SCIENCE', 'ARTIFICIAL INTELLIGENCE', 'ARTIFICIAL INTELLIGENCE', 'ARTIFICIAL INTELLIGENCE', 'SCIENCE', 'SCIENCE', 'ARTIFICIAL INTELLIGENCE', 'ARTIFICIAL INTELLIGENCE', 'ARTIFICIAL INTELLIGENCE', 'ARTIFICIAL INTELLIGENCE', 'SCIENCE', 'ARTIFICIAL INTELLIGENCE']\n"
     ]
    }
   ],
   "source": [
    "# Reformat to original categories\n",
    "\n",
    "# Replace single quotes with double quotes\n",
    "document_classes_list=json.loads(completion_text)\n",
    "\n",
    "# Define the dictionary\n",
    "categories = {'A': 'SCIENCE', 'B': 'ARTIFICIAL INTELLIGENCE', 'C': 'ART', 'D': 'HUMANITIES'}\n",
    "\n",
    "# Replace the letters with the categories\n",
    "lst = [categories[i] for i in document_classes_list]\n",
    "\n",
    "print(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case: Generating structured data in lists instead of JSON\n",
    "\n",
    "Often JSON is used as an output format of an LLM. It provides keys which are clear as to what the value being output is, and easy to use in downstream steps.\n",
    "\n",
    "However, a significant number of tokens can end up being generated writing out the keys over and over. This takes a significant amount of time for the LLM.\n",
    "\n",
    "A list is a more efficient data structure, as it simply uses the order of the elements to preserve the meaning. The list can then be restructured into a JSON (or dictionary) using code, if desired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A: Base Case: Using JSON\n",
    "\n",
    "**Time taken: 66 seconds**\n",
    "\n",
    "This is the typical structure used in online guides, tutorials, and many production applications. An advantage is that the meaning of each value is clearer, and it can be easier to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Tokens: 153\n",
      "Completion Tokens: 860\n",
      "Time taken: 47.09 seconds\n",
      "[\n",
      "    {\n",
      "        \"make\": \"Toyota\",\n",
      "        \"model\": \"Corolla\",\n",
      "        \"year\": 2022,\n",
      "        \"color\": \"blue\",\n",
      "        \"price\": 25000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Ford\",\n",
      "        \"model\": \"Mustang\",\n",
      "        \"year\": 2021,\n",
      "        \"color\": \"red\",\n",
      "        \"price\": 35000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Chevrolet\",\n",
      "        \"model\": \"Malibu\",\n",
      "        \"year\": 2019,\n",
      "        \"color\": \"black\",\n",
      "        \"price\": 22000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Honda\",\n",
      "        \"model\": \"Accord\",\n",
      "        \"year\": 2020,\n",
      "        \"color\": \"white\",\n",
      "        \"price\": 25000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Nissan\",\n",
      "        \"model\": \"Altima\",\n",
      "        \"year\": 2022,\n",
      "        \"color\": \"gray\",\n",
      "        \"price\": 26000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Mazda\",\n",
      "        \"model\": \"3\",\n",
      "        \"year\": 2022,\n",
      "        \"color\": \"blue\",\n",
      "        \"price\": 23000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Subaru\",\n",
      "        \"model\": \"Outback\",\n",
      "        \"year\": 2021,\n",
      "        \"color\": \"green\",\n",
      "        \"price\": 27000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Hyundai\",\n",
      "        \"model\": \"Elantra\",\n",
      "        \"year\": 2021,\n",
      "        \"color\": \"gold\",\n",
      "        \"price\": 20000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Kia\",\n",
      "        \"model\": \"Optima\",\n",
      "        \"year\": 2020,\n",
      "        \"color\": \"black\",\n",
      "        \"price\": 22000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Audi\",\n",
      "        \"model\": \"A3\",\n",
      "        \"year\": 2022,\n",
      "        \"color\": \"white\",\n",
      "        \"price\": 35000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"BMW\",\n",
      "        \"model\": \"3 Series\",\n",
      "        \"year\": 2021,\n",
      "        \"color\": \"red\",\n",
      "        \"price\": 40000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Mercedes\",\n",
      "        \"model\": \"C Class\",\n",
      "        \"year\": 2021,\n",
      "        \"color\": \"silver\",\n",
      "        \"price\": 41000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Tesla\",\n",
      "        \"model\": \"Model 3\",\n",
      "        \"year\": 2022,\n",
      "        \"color\": \"blue\",\n",
      "        \"price\": 42000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Volkswagen\",\n",
      "        \"model\": \"Golf\",\n",
      "        \"year\": 2020,\n",
      "        \"color\": \"green\",\n",
      "        \"price\": 23000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Jeep\",\n",
      "        \"model\": \"Wrangler\",\n",
      "        \"year\": 2021,\n",
      "        \"color\": \"black\",\n",
      "        \"price\": 30000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Dodge\",\n",
      "        \"model\": \"Charger\",\n",
      "        \"year\": 2022,\n",
      "        \"color\": \"white\",\n",
      "        \"price\": 29000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Lexus\",\n",
      "        \"model\": \"IS\",\n",
      "        \"year\": 2021,\n",
      "        \"color\": \"silver\",\n",
      "        \"price\": 37000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Cadillac\",\n",
      "        \"model\": \"XT5\",\n",
      "        \"year\": 2020,\n",
      "        \"color\": \"black\",\n",
      "        \"price\": 32000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Volvo\",\n",
      "        \"model\": \"XC60\",\n",
      "        \"year\": 2022,\n",
      "        \"color\": \"blue\",\n",
      "        \"price\": 40000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Infiniti\",\n",
      "        \"model\": \"Q50\",\n",
      "        \"year\": 2021,\n",
      "        \"color\": \"red\",\n",
      "        \"price\": 36000\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "system_message=\"\"\"\n",
    "You are an helpful AI assistant.\n",
    "\"\"\"\n",
    "prompt=f\"\"\"\n",
    "Generate 20 cars in a JSON format. Each car should have the following attributes: make, model, year, color, and price. The cars should be diverse in terms of make, model, and color.\n",
    "Example:\n",
    "[\n",
    "    {{\n",
    "        \"make\": \"Toyota\",\n",
    "        \"model\": \"Corolla\",\n",
    "        \"year\": 2022,\n",
    "        \"color\": \"blue\",\n",
    "        \"price\": 25000\n",
    "    }},\n",
    "    {{\n",
    "        \"make\": \"Ford\",\n",
    "        \"model\": \"Mustang\",\n",
    "        \"year\": 2021,\n",
    "        \"color\": \"red\",\n",
    "        \"price\": 35000\n",
    "    }},\n",
    "    ...\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "result,prompt_tokens,completion_tokens,completion_text,e2e_time=aoai_call(system_message,prompt,model)\n",
    "print(f\"Prompt Tokens: {prompt_tokens}\")\n",
    "print(f\"Completion Tokens: {completion_tokens}\")\n",
    "print(f\"Time taken: {e2e_time:.2f} seconds\")\n",
    "print(completion_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B: Using a list\n",
    "\n",
    "**Time taken: 28 seconds**\n",
    "\n",
    "Here the output is a list of lists, where each list contains the relevant parameters of the car in an expected order. This is significantly faster, as the LLM does not need to generate output tokens for each key in the dictionary.\n",
    "\n",
    "Once the task is completed, the list can be converted into a list programmatically, if so desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Tokens: 210\n",
      "Completion Tokens: 403\n",
      "Time taken: 26.39 seconds\n",
      "[\n",
      "    [\"Ford\", \"Mustang\", 2020, \"Red\", 30000],\n",
      "    [\"Chevrolet\", \"Camero\", 2019, \"Blue\", 28000],\n",
      "    [\"Dodge\", \"Charger\", 2018, \"Black\", 26000],\n",
      "    [\"Toyota\", \"Camry\", 2017, \"White\", 24000],\n",
      "    [\"Honda\", \"Accord\", 2016, \"Silver\", 22000],\n",
      "    [\"Nissan\", \"Maxima\", 2015, \"Grey\", 20000],\n",
      "    [\"BMW\", \"3 Series\", 2022, \"Blue\", 40000],\n",
      "    [\"Audi\", \"A4\", 2021, \"Red\", 38000],\n",
      "    [\"Mercedes\", \"C Class\", 2020, \"White\", 36000],\n",
      "    [\"Lexus\", \"IS\", 2019, \"Silver\", 34000],\n",
      "    [\"Acura\", \"TLX\", 2018, \"Black\", 32000],\n",
      "    [\"Infiniti\", \"Q50\", 2017, \"Grey\", 30000],\n",
      "    [\"Subaru\", \"Impreza\", 2016, \"Blue\", 28000],\n",
      "    [\"Jeep\", \"Cherokee\", 2022, \"Red\", 36000],\n",
      "    [\"Porsche\", \"911\", 2021, \"White\", 120000],\n",
      "    [\"Maserati\", \"Ghibli\", 2020, \"Silver\", 75000],\n",
      "    [\"Aston Martin\", \"DB11\", 2019, \"Black\", 200000],\n",
      "    [\"Rolls Royce\", \"Ghost\", 2018, \"White\", 320000],\n",
      "    [\"Bentley\", \"Continental\", 2017, \"Blue\", 220000],\n",
      "    [\"Tesla\", \"Model 3\", 2021, \"Red\", 49000]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "system_message=\"\"\"\n",
    "You are an helpful AI assistant.\n",
    "\"\"\"\n",
    "prompt=f\"\"\"\n",
    "Generate 20 cars in a list. Each car should have the following attributes: make, model, year, color, and price. The cars should be diverse in terms of make, model, and color. Output only exactly the list of cars, no additional text or comments.\n",
    "Example:\n",
    "[\n",
    "    [\n",
    "        \"the first element is the make of the car\",\n",
    "        \"the second element is the model of the car\",\n",
    "        \"the third element is the year of the car\",\n",
    "        \"the fourth element is the color of the car\",\n",
    "        \"the fifth element is the price of the car\"\n",
    "    ],\n",
    "    [\n",
    "        \"the first element is the make of the car\",\n",
    "        \"the second element is the model of the car\",\n",
    "        \"the third element is the year of the car\",\n",
    "        \"the fourth element is the color of the car\",\n",
    "        \"the fifth element is the price of the car\"\n",
    "    ],\n",
    "    ...\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "result,prompt_tokens,completion_tokens,completion_text,e2e_time=aoai_call(system_message,prompt,model)\n",
    "print(f\"Prompt Tokens: {prompt_tokens}\")\n",
    "print(f\"Completion Tokens: {completion_tokens}\")\n",
    "print(f\"Time taken: {e2e_time:.2f} seconds\")\n",
    "print(completion_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'make': 'Ford', 'model': 'Mustang', 'year': 2020, 'color': 'Red', 'price': 30000}, {'make': 'Chevrolet', 'model': 'Camero', 'year': 2019, 'color': 'Blue', 'price': 28000}, {'make': 'Dodge', 'model': 'Charger', 'year': 2018, 'color': 'Black', 'price': 26000}, {'make': 'Toyota', 'model': 'Camry', 'year': 2017, 'color': 'White', 'price': 24000}, {'make': 'Honda', 'model': 'Accord', 'year': 2016, 'color': 'Silver', 'price': 22000}, {'make': 'Nissan', 'model': 'Maxima', 'year': 2015, 'color': 'Grey', 'price': 20000}, {'make': 'BMW', 'model': '3 Series', 'year': 2022, 'color': 'Blue', 'price': 40000}, {'make': 'Audi', 'model': 'A4', 'year': 2021, 'color': 'Red', 'price': 38000}, {'make': 'Mercedes', 'model': 'C Class', 'year': 2020, 'color': 'White', 'price': 36000}, {'make': 'Lexus', 'model': 'IS', 'year': 2019, 'color': 'Silver', 'price': 34000}, {'make': 'Acura', 'model': 'TLX', 'year': 2018, 'color': 'Black', 'price': 32000}, {'make': 'Infiniti', 'model': 'Q50', 'year': 2017, 'color': 'Grey', 'price': 30000}, {'make': 'Subaru', 'model': 'Impreza', 'year': 2016, 'color': 'Blue', 'price': 28000}, {'make': 'Jeep', 'model': 'Cherokee', 'year': 2022, 'color': 'Red', 'price': 36000}, {'make': 'Porsche', 'model': '911', 'year': 2021, 'color': 'White', 'price': 120000}, {'make': 'Maserati', 'model': 'Ghibli', 'year': 2020, 'color': 'Silver', 'price': 75000}, {'make': 'Aston Martin', 'model': 'DB11', 'year': 2019, 'color': 'Black', 'price': 200000}, {'make': 'Rolls Royce', 'model': 'Ghost', 'year': 2018, 'color': 'White', 'price': 320000}, {'make': 'Bentley', 'model': 'Continental', 'year': 2017, 'color': 'Blue', 'price': 220000}, {'make': 'Tesla', 'model': 'Model 3', 'year': 2021, 'color': 'Red', 'price': 49000}]\n"
     ]
    }
   ],
   "source": [
    "# Programatically turn the list back into a dict (JSON)\n",
    "\n",
    "car_list=json.loads(completion_text)\n",
    "\n",
    "# Define the keys for the dictionaries\n",
    "keys = [\"make\", \"model\", \"year\", \"color\", \"price\"]\n",
    "\n",
    "# Convert the list of lists into a list of dictionaries\n",
    "dict_list = [dict(zip(keys, sublist)) for sublist in car_list]\n",
    "\n",
    "print(dict_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
