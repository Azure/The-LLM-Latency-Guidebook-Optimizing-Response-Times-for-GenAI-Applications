{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set max_tokens to be close to the expected value\n",
    "\n",
    "The guidance shared in the post (below) was tested using GPT-4. It suggests that setting the max_tokens parameter close to the expected output tokens can help reduce the latency of requests.\n",
    "\n",
    "https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/latency\n",
    "\n",
    "The results were not conclusive, showing only minor differences between the two tests. \n",
    "\n",
    "It is important to consider- the intent of this technique is not to truncate responses that are longer than average. For example, if 90% of responses are less than 200 tokens, and 10% are much longer, setting the max_tokens to 200 tokens will give an improvement to response times. However, this may not give a useful response, as it will be cutoff part way. \n",
    "\n",
    "The expectation is that for responses that output a number of generation tokens below the max_token thershold\n",
    "\n",
    "If you have identified a working implementation of this technique, please submit a PR!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Helper Functions and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "import json\n",
    "import time\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import copy\n",
    "import textwrap\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "def aoai_call(system_message, prompt, model, max_tokens):\n",
    "    client = AzureOpenAI(\n",
    "        api_version=os.getenv(\"API_VERSION\"),\n",
    "        azure_endpoint=os.getenv(\"AZURE_ENDPOINT\"),\n",
    "        api_key=os.getenv(\"API_KEY\")\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    e2e_time = end_time - start_time\n",
    "\n",
    "    result = json.loads(completion.model_dump_json(indent=2))\n",
    "    prompt_tokens = result[\"usage\"][\"prompt_tokens\"]\n",
    "    completion_tokens = result[\"usage\"][\"completion_tokens\"]\n",
    "    completion_text = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    return result, prompt_tokens, completion_tokens, completion_text, e2e_time\n",
    "model=os.getenv(\"MODELGPT432k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case: RAG\n",
    "\n",
    "A simple RAG use case has been used to test this technique.\n",
    "\n",
    "For the first A/B test, the end-to-end latency is measured as an average across several runs, as the difference appeared to not be significant and was difficult to discern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_documents=\"\"\"\n",
    "\n",
    "1. “Quantum Entanglement: Spooky Action at a Distance”\n",
    "Abstract:\n",
    "Quantum entanglement, a phenomenon that baffled even Einstein, lies at the heart of quantum mechanics. In this article, we delve into the mysterious world of entangled particles, exploring how they can be connected across vast distances instantaneously. From Bell’s theorem to quantum teleportation, we unravel the enigma of entanglement and its potential applications in quantum computing and secure communication.\n",
    "\n",
    "Introduction:\n",
    "Quantum entanglement defies classical intuition. Imagine two particles—say, electrons—created together and then separated by light-years. Remarkably, their properties remain intertwined, regardless of the distance between them. When one particle’s state changes, the other responds instantaneously, as if they share a hidden connection. But how does this “spooky action at a distance” work?\n",
    "\n",
    "Bell’s Theorem:\n",
    "Physicist John Bell proposed a test to determine whether entanglement was real or merely a statistical fluke. Experiments confirmed Bell’s predictions: the correlations between entangled particles violated classical limits. Quantum mechanics prevailed, and entanglement emerged as a fundamental property of the universe.\n",
    "\n",
    "Quantum Teleportation:\n",
    "Entanglement enables quantum teleportation—a process where information about one particle is transmitted to another, even if they are light-years apart. This isn’t “Star Trek” teleportation of matter; instead, it transfers quantum states. Researchers are harnessing this phenomenon for secure communication and quantum networks.\n",
    "\n",
    "Applications:\n",
    "Beyond teleportation, entanglement plays a pivotal role in quantum computing. Qubits, the building blocks of quantum computers, rely on entanglement for their power. Scientists are also exploring entanglement-based sensors, clocks, and cryptography.\n",
    "\n",
    "2. “CRISPR-Cas9: Rewriting the Genetic Code”\n",
    "Abstract:\n",
    "CRISPR-Cas9, a revolutionary gene-editing tool, has transformed biology and medicine. In this article, we explore the origins of CRISPR, its mechanism, and its impact on genetic research. From curing genetic diseases to creating designer organisms, CRISPR opens new frontiers in biotechnology.\n",
    "\n",
    "Introduction:\n",
    "Clustered Regularly Interspaced Short Palindromic Repeats (CRISPR) were initially discovered in bacteria as part of their immune system. Scientists soon realized that they could repurpose this system for precise gene editing. Enter CRISPR-Cas9—the Swiss Army knife of genetic manipulation.\n",
    "\n",
    "How It Works:\n",
    "CRISPR-Cas9 acts like molecular scissors. It uses a guide RNA to target specific DNA sequences, and the Cas9 protein cuts the DNA at that location. Researchers can then insert, delete, or modify genes with unprecedented accuracy. The simplicity and efficiency of CRISPR have revolutionized genetic research.\n",
    "\n",
    "Applications:\n",
    "Treating Genetic Diseases: CRISPR holds promise for curing genetic disorders like sickle cell anemia and cystic fibrosis. Clinical trials are underway.\n",
    "Agriculture: CRISPR can create crops resistant to pests, drought, and disease.\n",
    "Designer Babies?: Ethical debates surround using CRISPR for human enhancement.\n",
    "Conservation: CRISPR may help save endangered species by editing their genomes.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A: Setting max_tokens to 2000\n",
    "\n",
    "**Time taken: 1.9 seconds**\n",
    "\n",
    "The max_token parameter is set significantly higher than the requirement for this use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Tokens: 26\n",
      "Completion Tokens: 1\n",
      "Time taken: 1.69 seconds\n",
      "A\n",
      "Prompt Tokens: 26\n",
      "Completion Tokens: 1\n",
      "Time taken: 1.76 seconds\n",
      "A\n",
      "Prompt Tokens: 26\n",
      "Completion Tokens: 1\n",
      "Time taken: 1.47 seconds\n",
      "A\n",
      "Prompt Tokens: 26\n",
      "Completion Tokens: 1\n",
      "Time taken: 1.57 seconds\n",
      "A\n",
      "Prompt Tokens: 26\n",
      "Completion Tokens: 1\n",
      "Time taken: 1.66 seconds\n",
      "A\n",
      "Prompt Tokens: 26\n",
      "Completion Tokens: 1\n",
      "Time taken: 1.82 seconds\n",
      "A\n",
      "Prompt Tokens: 26\n",
      "Completion Tokens: 1\n",
      "Time taken: 1.68 seconds\n",
      "A\n",
      "Prompt Tokens: 26\n",
      "Completion Tokens: 1\n",
      "Time taken: 1.53 seconds\n",
      "A\n",
      "Prompt Tokens: 26\n",
      "Completion Tokens: 1\n",
      "Time taken: 1.51 seconds\n",
      "A\n",
      "Prompt Tokens: 26\n",
      "Completion Tokens: 1\n",
      "Time taken: 1.63 seconds\n",
      "A\n",
      "Average time taken: 1.63 seconds\n"
     ]
    }
   ],
   "source": [
    "system_message=\"\"\"\n",
    "You are a helpful AI assistant.\n",
    "\"\"\"\n",
    "prompt=f\"\"\"\n",
    "Return the character \"A\".\n",
    "\"\"\"\n",
    "\n",
    "e2e_times = []\n",
    "for _ in range(10):\n",
    "    result,prompt_tokens,completion_tokens,completion_text,e2e_time=aoai_call(system_message,prompt,model,2000)\n",
    "    print(f\"Prompt Tokens: {prompt_tokens}\")\n",
    "    print(f\"Completion Tokens: {completion_tokens}\")\n",
    "    print(f\"Time taken: {e2e_time:.2f} seconds\")\n",
    "    print(completion_text)\n",
    "    e2e_times.append(e2e_time)\n",
    "\n",
    "average_e2e_time = sum(e2e_times) / len(e2e_times)\n",
    "print(f\"Average time taken: {average_e2e_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B: Set max_tokens to 50 tokens\n",
    "\n",
    "**Time taken: 1.7 seconds**\n",
    "\n",
    "The max_tokens is set significantly lower, close to the expected number of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Tokens: 26\n",
      "Completion Tokens: 1\n",
      "Time taken: 1.79 seconds\n",
      "A\n",
      "Prompt Tokens: 26\n",
      "Completion Tokens: 1\n",
      "Time taken: 1.72 seconds\n",
      "A\n",
      "Prompt Tokens: 26\n",
      "Completion Tokens: 1\n",
      "Time taken: 1.45 seconds\n",
      "A\n",
      "Prompt Tokens: 26\n",
      "Completion Tokens: 1\n",
      "Time taken: 1.97 seconds\n",
      "A\n",
      "Prompt Tokens: 26\n",
      "Completion Tokens: 1\n",
      "Time taken: 1.62 seconds\n",
      "A\n",
      "Prompt Tokens: 26\n",
      "Completion Tokens: 1\n",
      "Time taken: 1.80 seconds\n",
      "A\n",
      "Prompt Tokens: 26\n",
      "Completion Tokens: 1\n",
      "Time taken: 1.87 seconds\n",
      "A\n",
      "Prompt Tokens: 26\n",
      "Completion Tokens: 1\n",
      "Time taken: 1.53 seconds\n",
      "A\n",
      "Prompt Tokens: 26\n",
      "Completion Tokens: 1\n",
      "Time taken: 1.85 seconds\n",
      "A\n",
      "Prompt Tokens: 26\n",
      "Completion Tokens: 1\n",
      "Time taken: 1.61 seconds\n",
      "A\n",
      "Average time taken: 1.72 seconds\n"
     ]
    }
   ],
   "source": [
    "system_message=\"\"\"\n",
    "You are a helpful AI assistant.\n",
    "\"\"\"\n",
    "prompt=f\"\"\"\n",
    "Return the character \"A\".\n",
    "\"\"\"\n",
    "\n",
    "e2e_times = []\n",
    "for _ in range(10):\n",
    "    result,prompt_tokens,completion_tokens,completion_text,e2e_time=aoai_call(system_message,prompt,model,50)\n",
    "    print(f\"Prompt Tokens: {prompt_tokens}\")\n",
    "    print(f\"Completion Tokens: {completion_tokens}\")\n",
    "    print(f\"Time taken: {e2e_time:.2f} seconds\")\n",
    "    print(completion_text)\n",
    "    e2e_times.append(e2e_time)\n",
    "\n",
    "average_e2e_time = sum(e2e_times) / len(e2e_times)\n",
    "print(f\"Average time taken: {average_e2e_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing benefits to Time-to-First Token and other metrics\n",
    "\n",
    "The initial test did not reveal a material benefit to the end to end latency.\n",
    "\n",
    "A more detailed test was set up to explore other metrics relating to latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "client = AzureOpenAI(\n",
    "    api_version=os.getenv(\"API_VERSION\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"API_KEY\")\n",
    ")\n",
    "\n",
    "# Initialize DataFrame\n",
    "\n",
    "def run_experiment(max_tokens,samples):\n",
    "    df = pd.DataFrame(columns=['e2e_time', 'time_to_first_token', 'average_tbt_duration','achieved_completion_chunks'])\n",
    "    \n",
    "\n",
    "\n",
    "    system_message=\"\"\"\n",
    "    You are a helpful AI assistant.\n",
    "    \"\"\"\n",
    "    prompt=f\"\"\"\n",
    "    Return the character A.\n",
    "    \"\"\"\n",
    "    for _ in range(samples):\n",
    "        start_time = time.time()\n",
    "\n",
    "        completion = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            stream=True,\n",
    "            max_tokens=max_tokens\n",
    "        )\n",
    "\n",
    "        e2e_start_time = time.time()\n",
    "\n",
    "        tbt_durations = []\n",
    "        previous_time = time.time()\n",
    "\n",
    "        for i, message in enumerate(completion):\n",
    "            if i==1:\n",
    "                time_to_first_token=time.time()-e2e_start_time\n",
    "\n",
    "            current_time = time.time()\n",
    "            tbt_durations.append(current_time - previous_time)\n",
    "            previous_time = current_time\n",
    "\n",
    "        average_tbt_duration = sum(tbt_durations) / len(tbt_durations)\n",
    "\n",
    "        e2e_end_time = time.time()\n",
    "        e2e_time = e2e_end_time - e2e_start_time\n",
    "        # print(time_to_first_token)\n",
    "        # print(tbt_durations)\n",
    "\n",
    "        # Create a DataFrame for the current row\n",
    "        current_df = pd.DataFrame({\n",
    "            'e2e_time': [e2e_time],\n",
    "            'time_to_first_token': [time_to_first_token],\n",
    "            'average_tbt_duration': [average_tbt_duration],\n",
    "            'achieved_completion_chunks': len(tbt_durations),\n",
    "        })\n",
    "\n",
    "        # Concatenate the current DataFrame with the main DataFrame\n",
    "        df = pd.concat([df, current_df], ignore_index=True)\n",
    "\n",
    "    # Print DataFrame\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/04/byk1dtp95sn0gjlx1gsgdqkw0000gn/T/ipykernel_32556/428186082.py:63: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, current_df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "high_max_tokens_df=run_experiment(2000,20)\n",
    "# low_max_tokens_df=run_experiment(300,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e2e_time</th>\n",
       "      <th>time_to_first_token</th>\n",
       "      <th>average_tbt_duration</th>\n",
       "      <th>achieved_completion_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.096534</td>\n",
       "      <td>0.096027</td>\n",
       "      <td>0.032059</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.100113</td>\n",
       "      <td>0.099034</td>\n",
       "      <td>0.033070</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.341751</td>\n",
       "      <td>0.340789</td>\n",
       "      <td>0.068270</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.162070</td>\n",
       "      <td>0.161486</td>\n",
       "      <td>0.053887</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.099334</td>\n",
       "      <td>0.098958</td>\n",
       "      <td>0.033035</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.126829</td>\n",
       "      <td>0.126391</td>\n",
       "      <td>0.042184</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.286629</td>\n",
       "      <td>0.285353</td>\n",
       "      <td>0.057238</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001540</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.353777</td>\n",
       "      <td>0.352790</td>\n",
       "      <td>0.070669</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.091511</td>\n",
       "      <td>0.091280</td>\n",
       "      <td>0.030452</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.078165</td>\n",
       "      <td>0.077590</td>\n",
       "      <td>0.025921</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.064705</td>\n",
       "      <td>0.063787</td>\n",
       "      <td>0.021323</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.071837</td>\n",
       "      <td>0.070674</td>\n",
       "      <td>0.023717</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.104743</td>\n",
       "      <td>0.103841</td>\n",
       "      <td>0.034729</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.115885</td>\n",
       "      <td>0.114751</td>\n",
       "      <td>0.038415</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.087250</td>\n",
       "      <td>0.086630</td>\n",
       "      <td>0.028933</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.325862</td>\n",
       "      <td>0.324419</td>\n",
       "      <td>0.108307</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.171937</td>\n",
       "      <td>0.171296</td>\n",
       "      <td>0.034333</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.093749</td>\n",
       "      <td>0.092571</td>\n",
       "      <td>0.031029</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.109082</td>\n",
       "      <td>0.108656</td>\n",
       "      <td>0.036273</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    e2e_time  time_to_first_token  average_tbt_duration  \\\n",
       "0   0.096534             0.096027              0.032059   \n",
       "1   0.100113             0.099034              0.033070   \n",
       "2   0.341751             0.340789              0.068270   \n",
       "3   0.162070             0.161486              0.053887   \n",
       "4   0.099334             0.098958              0.033035   \n",
       "5   0.126829             0.126391              0.042184   \n",
       "6   0.286629             0.285353              0.057238   \n",
       "7   0.001540             0.001029              0.000389   \n",
       "8   0.353777             0.352790              0.070669   \n",
       "9   0.091511             0.091280              0.030452   \n",
       "10  0.078165             0.077590              0.025921   \n",
       "11  0.064705             0.063787              0.021323   \n",
       "12  0.071837             0.070674              0.023717   \n",
       "13  0.104743             0.103841              0.034729   \n",
       "14  0.115885             0.114751              0.038415   \n",
       "15  0.087250             0.086630              0.028933   \n",
       "16  0.325862             0.324419              0.108307   \n",
       "17  0.171937             0.171296              0.034333   \n",
       "18  0.093749             0.092571              0.031029   \n",
       "19  0.109082             0.108656              0.036273   \n",
       "\n",
       "   achieved_completion_chunks  \n",
       "0                           3  \n",
       "1                           3  \n",
       "2                           5  \n",
       "3                           3  \n",
       "4                           3  \n",
       "5                           3  \n",
       "6                           5  \n",
       "7                           3  \n",
       "8                           5  \n",
       "9                           3  \n",
       "10                          3  \n",
       "11                          3  \n",
       "12                          3  \n",
       "13                          3  \n",
       "14                          3  \n",
       "15                          3  \n",
       "16                          3  \n",
       "17                          5  \n",
       "18                          3  \n",
       "19                          3  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_max_tokens_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e2e_time</th>\n",
       "      <th>time_to_first_token</th>\n",
       "      <th>average_tbt_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.100992</td>\n",
       "      <td>0.097004</td>\n",
       "      <td>0.030563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.048295</td>\n",
       "      <td>0.038386</td>\n",
       "      <td>0.011666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.057345</td>\n",
       "      <td>0.056483</td>\n",
       "      <td>0.018992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.094961</td>\n",
       "      <td>0.093883</td>\n",
       "      <td>0.030989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>0.149183</td>\n",
       "      <td>0.148146</td>\n",
       "      <td>0.040058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>0.166388</td>\n",
       "      <td>0.162287</td>\n",
       "      <td>0.049956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>0.243698</td>\n",
       "      <td>0.193258</td>\n",
       "      <td>0.063657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.263026</td>\n",
       "      <td>0.201001</td>\n",
       "      <td>0.067083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        e2e_time  time_to_first_token  average_tbt_duration\n",
       "count  20.000000            20.000000             20.000000\n",
       "mean    0.100992             0.097004              0.030563\n",
       "std     0.048295             0.038386              0.011666\n",
       "min     0.057345             0.056483              0.018992\n",
       "50%     0.094961             0.093883              0.030989\n",
       "90%     0.149183             0.148146              0.040058\n",
       "95%     0.166388             0.162287              0.049956\n",
       "99%     0.243698             0.193258              0.063657\n",
       "max     0.263026             0.201001              0.067083"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_max_tokens_df.describe(percentiles = [.5, 0.9, .95, .99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e2e_time</th>\n",
       "      <th>time_to_first_token</th>\n",
       "      <th>average_tbt_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.165456</td>\n",
       "      <td>0.164403</td>\n",
       "      <td>0.046039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.321768</td>\n",
       "      <td>0.321733</td>\n",
       "      <td>0.080006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>0.000620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.078550</td>\n",
       "      <td>0.077613</td>\n",
       "      <td>0.024106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>0.189198</td>\n",
       "      <td>0.188353</td>\n",
       "      <td>0.062854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>0.298322</td>\n",
       "      <td>0.297291</td>\n",
       "      <td>0.092914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>1.270729</td>\n",
       "      <td>1.269610</td>\n",
       "      <td>0.321260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.513830</td>\n",
       "      <td>1.512690</td>\n",
       "      <td>0.378347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        e2e_time  time_to_first_token  average_tbt_duration\n",
       "count  20.000000            20.000000             20.000000\n",
       "mean    0.165456             0.164403              0.046039\n",
       "std     0.321768             0.321733              0.080006\n",
       "min     0.002427             0.001521              0.000620\n",
       "50%     0.078550             0.077613              0.024106\n",
       "90%     0.189198             0.188353              0.062854\n",
       "95%     0.298322             0.297291              0.092914\n",
       "99%     1.270729             1.269610              0.321260\n",
       "max     1.513830             1.512690              0.378347"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_max_tokens_df.describe(percentiles = [.5, 0.9, .95, .99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "It is unclear whether this technique has had a benefit to the latency. It also adds a risk of truncating responses unintentionally, which may impact the effectiveness of the app.\n",
    "\n",
    "Only one use case and workload type was tested, and this is in no way a rigorous or exhaustive test."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
